{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  sentiment\n",
      "0     The bra is very nice and pretty.  The fabric i...          1\n",
      "1     Good, loved the sale. Amazing discount price a...          1\n",
      "2     Comfortable and fit was on point. Like the fac...          1\n",
      "3     Ordered my &#34;normal size&#34; and they are ...          0\n",
      "4     If I bought this I don't know what happened to...          0\n",
      "5     I got this for my son who is 6'2 and weighs ab...          1\n",
      "6     I hope the watch lives up to the Timex reputat...          1\n",
      "7     This is a beautiful watch, nicer in person tha...          1\n",
      "8     I rodered this shoe in a 5.5w BIG GIRL and rec...          0\n",
      "9     I am extremely upset with my new BM8180-03E be...          0\n",
      "10    Great bra for the money, I just wish there whe...          1\n",
      "11    Love how it fits, material feels good and stro...          1\n",
      "12    Size: Perfect fit. Shipment: very good. Qualit...          1\n",
      "13    Fit was quite nice, but the center snap/button...          0\n",
      "14    Yelp, I guarantee this costume will rip on the...          0\n",
      "15    I love the light weight aspect of Saucony shoe...          0\n",
      "16    A warm sock, but not so heavy that you cannot ...          1\n",
      "17    This is an update to my first review.  The ban...          1\n",
      "18    Bates, Bates, Bates, being former military thi...          0\n",
      "19    If you have wide hips with any fat on them, av...          0\n",
      "20    We bought a medium for 9 year old. It is tiny!...          0\n",
      "21    The Heather Latte in Large looked like a baggy...          0\n",
      "22    I have bought Shadowline long gowns for severa...          1\n",
      "23    I'm a large size (34 E) and have a Panache spo...          0\n",
      "24    These are a very comfortable product.  I can h...          1\n",
      "25    Just your basic, hi top chucks. I have them in...          1\n",
      "26    ****I am also sending this to Timex Customer S...          0\n",
      "27    Ordered a large size..got overlarge. Fabric is...          0\n",
      "28    I do not recommend. Silver foam and creams wor...          0\n",
      "29    I love the way this bra looks, fits and  washe...          1\n",
      "...                                                 ...        ...\n",
      "7970  I bought these ignoring the poor reviews since...          0\n",
      "7971  I bought this ring and received it timely, I a...          0\n",
      "7972  This robe is so flimsy and cheap. You can hold...          0\n",
      "7973  I ride horses and some of them are a little on...          1\n",
      "7974  The item looks like the photo shown.  I am 5'7...          0\n",
      "7975  The sizing is seriously off on this item. I am...          0\n",
      "7976  If you don't want to put on your spectacles ev...          1\n",
      "7977  Good price point - wroks well. Great aid in te...          1\n",
      "7978  I have other size 30 shorts that fit comfortab...          0\n",
      "7979  I've been searching unsuccessfully for a few y...          1\n",
      "7980  I bought this for a trip to Disney, because I ...          1\n",
      "7981  I really wanted to like this bra as it is very...          0\n",
      "7982  I wanted to buy them but the size chart link g...          0\n",
      "7983  They're a little loose, but what the heck---th...          1\n",
      "7984  This bra pokes you in the armpits.  I usually ...          0\n",
      "7985  I bought big and I am glad I did.  My son wear...          1\n",
      "7986  the slipper is nice and soft but there is no r...          0\n",
      "7987  I stand on my feet for 7 hours at a time in a ...          1\n",
      "7988  It's a fine watch, but don't rely too much on ...          0\n",
      "7989  I wanted a watch that I didn't have to worry a...          0\n",
      "7990  Never GOT this item - but gave a 1 STAR becaus...          0\n",
      "7991  I love to wear them.  Fit very well and are ve...          1\n",
      "7992  The pantyhose is not super high quality, I wou...          1\n",
      "7993  We bought these wings to go with the Buzz Ligh...          1\n",
      "7994  This is a nice wallet until you put a 'few' ca...          0\n",
      "7995  I love Birkenstock sandals, but Amazon keeps s...          0\n",
      "7996  These undies are well-made and very comfortabl...          1\n",
      "7997  Got dooped by the reviews on how they'd fit.  ...          0\n",
      "7998         Pathetic service. The staff was very rude.          0\n",
      "7999  The stores were full and the staff was so busy...          0\n",
      "\n",
      "[8000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#loading reviews and sentiments in to the dataframe\n",
    "import pandas as pd\n",
    "filename = 'C:/Users/AHMED/Downloads/final-output-sentiments.csv'\n",
    "reviews = pd.read_csv(filename)\n",
    "print(reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the column headings\n",
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4000\n",
       "0    4000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count for both classes\n",
    "reviews['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the datatypes of the two columns\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "#is_string_dtype(reviews['reviewText'])\n",
    "#is_numeric_dtype(reviews['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleansing\n",
    "import re\n",
    "for index, row in reviews.iterrows():\n",
    "    review = row['reviewText']\n",
    "    review = re.sub(\"[^a-zA-Z' ]+\", '', str(review)).lower()\n",
    "    #review = ''.join([i for i in str(review) if not i.isdigit()])\n",
    "    #review = re.sub(\"[!@#$+%*:()-]\", '', str(review))\n",
    "    reviews.at[index, 'reviewText'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintReviews():\n",
    "    print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding out the unique words\n",
    "def UniqueWords():\n",
    "    uniqueWords = list(reviews['reviewText'].str.split(' ', expand=True).stack().unique())\n",
    "    print(len(uniqueWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#removing words that are not found in the english dictionary (optional)\n",
    "from nltk.corpus import wordnet\n",
    "for index, row in reviews.iterrows():\n",
    "    review = row['reviewText']\n",
    "    review = ' '.join([w for w in str(review).split() if wordnet.synsets(w)])\n",
    "    reviews.at[index, 'reviewText'] = review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AHMED\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a list of stopWords\n",
    "from nltk.corpus import stopwords\n",
    "oldStopWords = stopwords.words('english')\n",
    "exceptions = ['no', 'nor', 'not','don', \"don't\", 't', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "stopWords = [word for word in oldStopWords if word not in exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words\n",
    "for index, row in reviews.iterrows():\n",
    "    review = row['reviewText']\n",
    "    wordList = review.split() \n",
    "    filteredWords = [word for word in wordList if word not in stopWords]\n",
    "    review = ' '.join(filteredWords)\n",
    "    reviews.at[index, 'reviewText'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11028\n"
     ]
    }
   ],
   "source": [
    "UniqueWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def StemSentence(reviews):\n",
    "    for index, row in reviews.iterrows():\n",
    "        review = row['reviewText']\n",
    "        wordsTokens = word_tokenize(review)\n",
    "        stemmedSentence=[]\n",
    "        for word in wordsTokens:\n",
    "            stemmedSentence.append(porter.stem(word))\n",
    "            stemmedSentence.append(\" \")\n",
    "        review = \"\".join(stemmedSentence)\n",
    "        reviews.at[index, 'reviewText'] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6980\n"
     ]
    }
   ],
   "source": [
    "StemSentence(reviews)\n",
    "UniqueWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  sentiment\n",
      "0     bra nice pretti fabric stiff rather itchi wash...          1\n",
      "1     good love sale amaz discount price excel qualiti           1\n",
      "2     comfort fit point like fact not visibl top ple...          1\n",
      "3     order normal size full size width small mayb b...          0\n",
      "4                              bought know happen wear           0\n",
      "5     got son weigh coat fit great say comfort warm ...          1\n",
      "6     hope watch live reput cost much still run open...          1\n",
      "7     beauti watch nicer person pictur love two tone...          1\n",
      "8     shoe w big girl babi shoe shoe look like pictu...          0\n",
      "9     extrem upset new second hand not align mark ar...          0\n",
      "10         great bra money wish color choos size great           1\n",
      "11    love fit materi feel good strong beef pocket w...          1\n",
      "12    size perfect fit shipment good color exactli p...          1\n",
      "13    fit quit nice center broke first time put know...          0\n",
      "14    yelp guarante costum rip day play realli cheap...          0\n",
      "15    love light weight aspect shoe favorit pair sho...          0\n",
      "16    warm sock not heavi wear indoor well love wear...          1\n",
      "17    updat first review band show sign wear month d...          1\n",
      "18    bate bate bate former militari common shoe par...          0\n",
      "19    wide hip fat avoid panti order medium fit fit ...          0\n",
      "20    bought medium year old cheap materi weak wide ...          0\n",
      "21    heather latt larg look like baggi paper bag we...          0\n",
      "22    bought long gown sever year love comfort last ...          1\n",
      "23    larg size e panach sport bra absolut love surp...          0\n",
      "24    comfort product hardli tell design great avoid...          1\n",
      "25    basic hi top chuck almost everi color good sho...          1\n",
      "26    also send custom mani review love ironman watc...          0\n",
      "27    order larg overlarg fabric great look good pic...          0\n",
      "28    not recommend silver foam cream work much bett...          0\n",
      "29    love way bra look fit wash second time order g...          1\n",
      "...                                                 ...        ...\n",
      "7970  bought ignor poor review sold amazon neg revie...          0\n",
      "7971  bought ring receiv time alway buy size ring fi...          0\n",
      "7972  robe flimsi cheap hold light see layer lint ma...          0\n",
      "7973  ride hors littl rough side come trot feel tota...          1\n",
      "7974  item look like photo shown lb one size fit wel...          0\n",
      "7975  size serious item small side prefer bra alway ...          0\n",
      "7976  want put spectacl everi time want know time on...          1\n",
      "7977  good price point well great aid teach year old...          1\n",
      "7978  size short fit comfort tight waist hip probabl...          0\n",
      "7979  search unsuccess year french purs style wallet...          1\n",
      "7980  bought trip disney read keep toiletri counter ...          1\n",
      "7981  realli want like bra pretti howev extrem scrat...          0\n",
      "7982  want buy size chart link gave size chest size ...          0\n",
      "7983           littl loos stay long love comfi attract           1\n",
      "7984  bra poke armpit usual buy mostli easiest find ...          0\n",
      "7985  bought big glad son wear four bought littl gro...          1\n",
      "7986  slipper nice soft no room toe like pictur show...          0\n",
      "7987  stand feet hour time profession job shoe w wal...          1\n",
      "7988  fine watch reli much water resist label simila...          0\n",
      "7989  want watch worri activ cautiou easili ding wel...          0\n",
      "7990  never got item gave star repli supplier tri se...          0\n",
      "7991  love wear fit well comfort look realli nice we...          1\n",
      "7992  pantyhos not super high qualiti expect rip not...          1\n",
      "7993  bought wing go buzz delux costum realli made c...          1\n",
      "7994  nice wallet put card card holder insid made le...          0\n",
      "7995  love sandal amazon keep send soft instead orig...          0\n",
      "7996  undi comfort leg elast cover fabric best panti...          1\n",
      "7997  got review fit compani need get togeth man min...          0\n",
      "7998                          pathet servic staff rude           0\n",
      "7999               store full staff busi not attend us           0\n",
      "\n",
      "[8000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "PrintReviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewText', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['reviews'] = reviews['reviewText'].values\n",
    "df['sentiment'] = reviews['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bra nice pretti fabric stiff rather itchi wash...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good love sale amaz discount price excel qualiti</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comfort fit point like fact not visibl top ple...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>order normal size full size width small mayb b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bought know happen wear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment\n",
       "0  bra nice pretti fabric stiff rather itchi wash...          1\n",
       "1  good love sale amaz discount price excel qualiti           1\n",
       "2  comfort fit point like fact not visibl top ple...          1\n",
       "3  order normal size full size width small mayb b...          0\n",
       "4                           bought know happen wear           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets start training Models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Model\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "cv = CountVectorizer(ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "#print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the reviews with the model\n",
    "text_counts= cv.fit_transform(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training data into 70% , while the test into 30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ngram, X_test_ngram, y_train_ngram, y_test_ngram = train_test_split(\n",
    "    text_counts, df['sentiment'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.8766666666666667\n"
     ]
    }
   ],
   "source": [
    "#Text classification using TF-IDF\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Generation Using Multinomial Naive Bayes\n",
    "clf = MultinomialNB().fit(X_train_ngram, y_train_ngram)\n",
    "\n",
    "\n",
    "predicted= clf.predict(X_test_ngram)\n",
    "\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test_ngram, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf=TfidfVectorizer()\n",
    "\n",
    "text_tf= tf.fit_transform(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(\n",
    "    text_tf, df['sentiment'], test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.8783333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Generation Using Multinomial Naive Bayes\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tf, y_train_tf)\n",
    "predicted= clf.predict(X_test_tf)\n",
    "print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test_tf, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM for n-gram bow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.6483333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC().fit(X_train_ngram, y_train_ngram)\n",
    "predicted_SVM = clf.predict(X_test_ngram)\n",
    "print(\"SVM:\",metrics.accuracy_score(y_test_ngram, predicted_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM for tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.49541666666666667\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC().fit(X_train_tf, y_train_tf)\n",
    "predicted_SVM = clf.predict(X_test_tf)\n",
    "print(\"SVM:\",metrics.accuracy_score(y_test_tf, predicted_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for ngram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create KNeighbors classifier object model \n",
    "model = KNeighborsClassifier(n_neighbors=10) # default value for n_neighbors is 5\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_ngram, y_train_ngram)\n",
    "#Predict Output\n",
    "predictedm= model.predict(X_test_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.7033333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN:\",metrics.accuracy_score(y_test_ngram, predictedm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf knn\n",
    "\n",
    "#Import Library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create KNeighbors classifier object model \n",
    "model = KNeighborsClassifier(n_neighbors=10) # default value for n_neighbors is 5\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_tf, y_train_tf)\n",
    "#Predict Output\n",
    "predictedm= model.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.7958333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN:\",metrics.accuracy_score(y_test_tf, predictedm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest , n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create Random Forest object\n",
    "model = RandomForestClassifier()\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_ngram, y_train_ngram)\n",
    "#Predict Output\n",
    "predicted_model = model.predict(X_test_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Forest: 0.8020833333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Rand Forest:\",metrics.accuracy_score(y_test_ngram, predicted_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AHMED\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create Random Forest object\n",
    "model = RandomForestClassifier()\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_tf, y_train_tf)\n",
    "#Predict Output\n",
    "predicted_model = model.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Forest: 0.7941666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Rand Forest:\",metrics.accuracy_score(y_test_tf, predicted_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G-Boost N gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create Gradient Boosting Classifier object\n",
    "model= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_ngram, y_train_ngram)\n",
    "#Predict Output\n",
    "predicted_mode = model.predict(X_test_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost: 0.8304166666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"GBoost:\",metrics.accuracy_score(y_test_ngram, predicted_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G-Boost tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create Gradient Boosting Classifier object\n",
    "model= GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(X_train_tf, y_train_tf)\n",
    "#Predict Output\n",
    "predicted_mode = model.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost: 0.8204166666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"GBoost:\",metrics.accuracy_score(y_test_tf, predicted_mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
